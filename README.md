# Dockyard

Run multiple isolated Docker daemons on a single host, each with its own network, storage, and socket — without touching the system Docker.

## Why?

The stock Docker daemon is a singleton. You get one `dockerd`, one bridge, one set of iptables rules. If you need isolation between workloads — different runtimes, different networks, different storage — you're stuck with hacks or heavyweight VMs.

Dockyard spins up fully independent Docker instances that:

- **Run sysbox-runc by default** — containers that can run systemd, Docker-in-Docker, and other system workloads without `--privileged`
- **Coexist peacefully** — each instance gets its own bridge, subnet, containerd, socket, and data directory. No shared state, no conflicts
- **Manage their own firewall rules** — no more iptables chain clobbering between daemons (a real problem with multiple dockerd instances)
- **Survive reboots** — systemd services with proper dependency ordering, automatic restart, and clean teardown
- **Install in seconds** — one command generates config, another downloads Docker + sysbox binaries, generates a self-contained systemd service, and starts everything

## Install

```bash
curl -fsSL https://raw.githubusercontent.com/thieso2/dockyard/main/dist/dockyard.sh -o dockyard.sh
chmod +x dockyard.sh
```

## Quick Start

```bash
# Generate a config with randomized, conflict-free networks
./dockyard.sh gen-env

# Create instance (downloads Docker + sysbox binaries, sets up systemd)
sudo ./dockyard.sh create

# Run a container (uses sysbox-runc automatically)
/dockyard/bin/docker run --rm -it alpine ash
```

## Multiple Instances

Each instance needs its own config file with unique values. Use `gen-env` with overrides to create them:

```bash
# First instance (defaults: dy_ prefix, /dockyard root)
./dockyard.sh gen-env
sudo ./dockyard.sh create

# Second instance (custom prefix and root)
DOCKYARD_DOCKER_PREFIX=tc_ DOCKYARD_ROOT=/docker2 DOCKYARD_ENV=./docker2.env ./dockyard.sh gen-env
DOCKYARD_ENV=./docker2.env sudo -E ./dockyard.sh create
```

`gen-env` randomizes bridge and pool networks from `172.16.0.0/12`, checks for conflicts against `ip route` and existing installations, and writes a `dockyard.env`. Each instance runs independently with its own systemd service (`dy_docker`, `tc_docker`, etc.), its own bridge, and its own iptables rules scoped to its bridge interface.

## Configuration Reference

A `dockyard.env` defines exactly six variables. Everything else is derived.

**Minimal** — the bare values, as generated by `gen-env`:

```bash
DOCKYARD_ROOT=/dockyard
DOCKYARD_DOCKER_PREFIX=dy_
DOCKYARD_BRIDGE_CIDR=172.22.147.1/24
DOCKYARD_FIXED_CIDR=172.22.147.0/24
DOCKYARD_POOL_BASE=172.28.0.0/16
DOCKYARD_POOL_SIZE=24
```

**Annotated** — the same file with all variables explained:

```bash
# Dockyard instance configuration
# Generated by: ./dockyard.sh gen-env

# Base directory for all instance files.
# Contains bin/, etc/, lib/, log/, and run/ subdirectories.
# Must be unique per instance on the same host.
DOCKYARD_ROOT=/dockyard

# Prefix applied to every per-instance host resource:
#   Linux bridge:      ${PREFIX}docker0         (e.g. dy_docker0)
#   systemd service:   ${PREFIX}docker.service  (e.g. dy_docker.service)
#   system user/group: ${PREFIX}docker           (e.g. dy_docker)
# Must be unique per instance on the same host.
DOCKYARD_DOCKER_PREFIX=dy_

# IP address assigned to the bridge interface, with prefix length.
# Containers on this instance use it as their default gateway.
# Must be within 172.16.0.0/12 and unique across all instances.
DOCKYARD_BRIDGE_CIDR=172.22.147.1/24

# Container subnet (Docker's "fixed CIDR"). Must contain the bridge
# address above. Used to scope the NAT MASQUERADE iptables rule.
DOCKYARD_FIXED_CIDR=172.22.147.0/24

# Base subnet for user-defined networks (created with `docker network create`).
# Must be within 172.16.0.0/12, use a different second octet from BRIDGE_CIDR,
# and be unique across all instances on the host.
DOCKYARD_POOL_BASE=172.28.0.0/16

# Prefix length carved from POOL_BASE for each user-defined network.
# 24 means every `docker network create` gets a /24 from the pool.
DOCKYARD_POOL_SIZE=24
```

## Commands

```bash
./dockyard.sh gen-env [--nocheck]                            # Generate dockyard.env
sudo ./dockyard.sh create [--no-systemd] [--no-start]       # Create instance
sudo ./dockyard.sh enable                                     # Install systemd service
sudo ./dockyard.sh disable                                    # Remove systemd service
sudo ./dockyard.sh start                                      # Start manually (no systemd)
sudo ./dockyard.sh stop                                       # Stop manually (no systemd)
./dockyard.sh status                                          # Show diagnostics
sudo ./dockyard.sh verify                                     # Smoke-test a running instance
sudo ./dockyard.sh destroy                                    # Remove instance completely
```

All commands except `gen-env` require a config file. Lookup order:
1. `$DOCKYARD_ENV` if set → use that file
2. `./dockyard.env` in current directory
3. `../etc/dockyard.env` relative to the script (for the installed copy)
4. `$DOCKYARD_ROOT/etc/dockyard.env`

## What Gets Installed

The installer downloads static binaries (cached in `.tmp/` for repeated installs):

| Software | Version | Binaries |
|----------|---------|----------|
| [Docker CE](https://download.docker.com/linux/static/stable/x86_64/) | 29.2.1 | dockerd, containerd, docker, ctr, runc, etc. |
| [Docker Rootless Extras](https://download.docker.com/linux/static/stable/x86_64/) | 29.2.1 | dockerd-rootless, vpnkit, rootlesskit, etc. |
| [Sysbox fork](https://github.com/thieso2/sysbox) | 0.6.7.9-tc | sysbox-mgr, sysbox-fs, sysbox-runc (all per-instance) |

All three sysbox binaries are per-instance. There is no shared sysbox host daemon.

```
${DOCKYARD_ROOT}/                       # owned by ${PREFIX}docker user/group
├── bin/                                # dockerd, containerd, sysbox-mgr, sysbox-fs,
│                                       # sysbox-runc, docker (DOCKER_HOST wrapper), dockyard.sh, dockyardctl→dockyard.sh
├── etc/
│   ├── daemon.json                     # Daemon configuration
│   └── dockyard.env                    # Copy of config (written by create)
├── lib/
│   ├── docker/                         # Images, containers, volumes
│   │   └── containerd/
│   ├── sysbox/                         # sysbox-mgr data-root + sysbox-fs mountpoint
│   └── docker-config/                  # DOCKER_CONFIG dir (auth, config.json)
├── log/                                # containerd.log, dockerd.log, sysbox-mgr.log, sysbox-fs.log
└── run/                                # All runtime sockets + PIDs
    ├── docker.sock                     # Docker API socket (root:${PREFIX}docker 660)
    ├── dockerd.pid
    ├── containerd/
    │   └── containerd.sock
    └── sysbox/                         # Per-instance sysbox sockets + PID files
        ├── sysmgr.sock
        ├── sysfs.sock
        ├── sysbox-mgr.pid
        └── sysbox-fs.pid

/etc/systemd/system/${PREFIX}docker.service   # Per-instance docker unit (no shared sysbox unit)
/etc/apparmor.d/local/fusermount3             # Per-instance AppArmor block
```

The systemd service file is generated with all paths hardcoded at create time. It has no dependency on this repository — you can delete the repo after creation and everything keeps running.

## How Networking Works

Each instance creates its own Linux bridge and manages its own iptables rules. Docker's built-in iptables management is disabled (`--iptables=false`) because multiple daemons fight over shared chain names like `DOCKER-FORWARD` — whichever starts last wins and breaks the others.

Instead, each service adds four rules on startup and removes them on shutdown:

```
iptables -I FORWARD -i dy_docker0 -o dy_docker0 -j ACCEPT                              # container ↔ container
iptables -I FORWARD -i dy_docker0 ! -o dy_docker0 -j ACCEPT                             # container → internet
iptables -I FORWARD -o dy_docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT   # internet → container (replies)
iptables -t nat -I POSTROUTING -s 172.30.0.0/24 ! -o dy_docker0 -j MASQUERADE           # NAT for outbound
```

Every rule is scoped to the instance's bridge name, so instances can never interfere with each other or with the system Docker.

## Accessing the System Docker

Each dockyard instance includes a `docker` wrapper that sets the correct `DOCKER_HOST` automatically:

```bash
/dockyard/bin/docker ps      # dockyard instance
docker ps                     # system docker (unchanged)
```

Or use `DOCKER_HOST` directly:

```bash
export DOCKER_HOST=unix:///dockyard/run/docker.sock
```

## Why Sysbox is Forked

Nestybox sysbox 0.6.7 CE hardcodes its socket paths (`/run/sysbox/sysmgr.sock`, `/run/sysbox/sysfs.sock`) with no flag to change them. Only one sysbox-mgr + sysbox-fs pair can run per host, which conflicts with the goal of fully independent per-instance isolation.

The fork (`github.com/thieso2/sysbox`, version `0.6.7.9-tc`) adds `--run-dir <dir>` to all three sysbox binaries. Each dockyard instance points its sysbox pair at `${DOCKYARD_ROOT}/run/sysbox/`, giving N fully isolated sysbox instances on the same host. `--run-dir` is passed via `runtimeArgs` in `daemon.json` — no wrapper script needed.

## Prerequisites

- **Not Ubuntu 25.10** — Ubuntu 25.10's kernel (`6.17.0-14-generic`) is **not compatible**: it carries a patch that prevents `mount --make-private /` inside a user namespace, causing sysbox-runc to fail with `EPERM`. Mainline kernels 6.16, 6.17, and 6.18 are all confirmed working. Replace the Ubuntu 25.10 kernel with a mainline build from `kernel.ubuntu.com/mainline` to use dockyard on that distro. See [FINDINGS.md](FINDINGS.md) for details.
- Linux with systemd
- x86_64 architecture (arm64 not yet supported)
- `curl` and `tar` for binary downloads
- `iptables` and `rsync` (required by sysbox; present on Ubuntu 24.04, may need `apt-get install -y iptables rsync` on Ubuntu 25.04+)
- Root access for installation

Dockyard downloads and manages sysbox itself — no system-wide sysbox installation required.

## Destroy

```bash
sudo ./dockyard.sh destroy

# For a non-default instance
DOCKYARD_ENV=./docker2.env sudo -E ./dockyard.sh destroy
```

This stops the daemon, disables the systemd service, and removes all data including images and containers.

## Related Projects

| Project | What it does | How it differs |
|---------|-------------|----------------|
| [Sysbox (upstream)](https://github.com/nestybox/sysbox) | OCI runtime enabling rootless system workloads (Docker-in-Docker, systemd) inside containers | Dockyard uses a fork (`github.com/thieso2/sysbox`) that adds `--run-dir` for per-instance isolation |
| [multidocker](https://github.com/AkihiroSuda/multidocker) | Run multiple Docker daemons for testing different versions | Closest overlap — but test-oriented, no iptables isolation or systemd integration |
| [Kata Containers](https://github.com/kata-containers/kata-containers) | Lightweight VMs via KVM that look like containers | VM-level isolation per container, heavier overhead, different trust model |
| [gVisor](https://github.com/google/gvisor) | User-space application kernel intercepting syscalls (`runsc`) | Sandboxes individual containers, doesn't address multi-daemon orchestration |
| [Firecracker](https://github.com/firecracker-microvm/firecracker) | MicroVM monitor for serverless workloads (powers AWS Lambda) | Per-workload micro-VMs, no Docker API — needs containerd integration |
| [RootlessKit](https://github.com/rootless-containers/rootlesskit) | Fake-root via user namespaces for rootless Docker/Kubernetes | Makes a single daemon rootless — could be combined with Dockyard |

Dockyard's niche: multi-daemon orchestration with per-instance network isolation, sysbox-runc as default runtime, and self-contained systemd services.

## Authorship

This project was written entirely by [Claude](https://claude.ai) (Anthropic). [Thies C. Arntzen](https://github.com/thieso2) provided direction and requirements as navigator.

## License

MIT License — see [LICENSE](LICENSE) for details.
